{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work on Compensatory Indels\n",
    "**Mark Richard, with Yaniv Brandvain**\n",
    "\n",
    "The current state of the work has been to extend methods used on 4 individuals to a much larger data-set involving 180 individuals. This large data set is based on a [2013 paper](http://www.nature.com/ng/journal/v45/n8/full/ng.2678.html?foxtrotcallback=true) by the Nordborg research group (first author Long). The GitHub site that contains the data is [here](https://github.com/Gregor-Mendel-Institute/swedish-genomes).\n",
    "\n",
    "This document outlines the code and procceses used to recreate the results from the Long 2013 paper, and hopefully extend them.\n",
    "\n",
    "*Note: The code that follows is very dependent on the authors file system. This is as much a note to the author to change the structure of the code to make it more readily useable for anyone.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a useable annotation file\n",
    "\n",
    "On the GitHub site, the annotation file in the /Indel/Original folder was downloaded. The choice was made to not use the imputed data, as it was not consistently available across all datasets.\n",
    "\n",
    "The annotation file consists of sets of 2 lines: one line defining the beginning of an indel, and one line defining the end of the same indel. Many of these indels go across genes; we are only interested in looking at indels that lie entirely inside a single gene, and so the following code was used to create a new annotation file (adjustedAnnotation) that only contained indels that lie entirely inside a single gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('/home/mdrichard05/Dropbox/CompensatoryIndels/Data/Genomes/samtools.2.1.s.filled.e.noimpute.annotation')\n",
    "newFile = open('/home/mdrichard05/Dropbox/CompensatoryIndels/Data/Processed/adjustedAnnotation.txt','w')\n",
    "fileList = []\n",
    "for i in file:\n",
    "    if ';' not in i.strip('\\n').split('\\t')[7]:\n",
    "        fileList.append(i.strip('\\n').split('\\t'))\n",
    "\n",
    "for i in fileList:\n",
    "    for j in i:\n",
    "        newFile.write(j)\n",
    "        newFile.write('\\t')\n",
    "    newFile.write('\\n')\n",
    "\n",
    "file.close()\n",
    "newFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code makes use of the fact that the original annotation file separates intergenic information by semicolons: if an indel lies in more than one gene, there will be a semicolon in that column. So, we want all indels that do *not* have a semicolon in the relevant column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the Annotation and Info files\n",
    "\n",
    "The next step was to adjust the original .info file (this contains a list of each indel, one per line, detailing its location, length, the specific event, and whether it was an insertion or deletion). We only took the indels that were left in the adjusted annotation file (i.e. those that lie entirely in a single gene), and created a new file, 180StrainsRead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataSource = open('/home/mdrichard05/Dropbox/CompensatoryIndels/Data/Genomes/samtools.2.1.s.filled.e.noimpute.info')\n",
    "annot= open('/home/mdrichard05/Dropbox/CompensatoryIndels/Data/Processed/adjustedAnnotation.txt')\n",
    "newDataFile = open('/home/mdrichard05/Dropbox/CompensatoryIndels/Data/Processed/180StrainsRead.txt','w')\n",
    "\n",
    "#sort into list, keeping only chrom, loc, size, bases\n",
    "\n",
    "dataList = []\n",
    "for i in dataSource:\n",
    "    dataList.append(i.strip('\\n').split('\\t'))\n",
    "del dataList[0]\n",
    "del dataList[0]\n",
    "\n",
    "anList = []\n",
    "for i in annot:\n",
    "    anList.append(i.strip('\\n').split('\\t'))\n",
    "    \n",
    "anDict = {}\n",
    "for i in anList:\n",
    "    anDict[(i[0],i[1])] = i[7]\n",
    "\n",
    "for i in dataList:\n",
    "    newDataFile.write(i[0])\n",
    "    newDataFile.write('\\t')\n",
    "    newDataFile.write(str(i[1]))\n",
    "    newDataFile.write('\\t')\n",
    "    if str(i[3][0]) == '-':\n",
    "        newDataFile.write('-' + str(i[2]))\n",
    "        newDataFile.write('\\t')\n",
    "    else:\n",
    "        newDataFile.write(str(i[2]))\n",
    "        newDataFile.write('\\t')\n",
    "    newDataFile.write(str(i[3]))\n",
    "    newDataFile.write(str('\\t'))\n",
    "    if (i[0],i[1]) in anDict:\n",
    "        newDataFile.write(str(anDict[(i[0],i[1])]))\n",
    "    newDataFile.write('\\n')\n",
    "    \n",
    "\n",
    "dataSource.close()\n",
    "newDataFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is doing nothing particularly interesting. The only important thing to note is that the adjustedAnnotation file (`annot` in the code) is split into *pairs* of lines, and the first line in each pair corresponds to some line in the .info original file (`dataSource` in the code). The lines in `dataSource` that happen to be found in `annot` are just put into the 180StrainsRead file (`newDataFile` in the code), with some columns being truncated, and the added bonus of the length of the indel being denoted as positive or negative (for an insertion vs. deletion)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Lengths to individual data\n",
    "\n",
    "The next step was to take the original .csv file, which contains the information on whether each of the 180 individuals have a particular indel, and match it up with the adjusted annotation files, as well as include the length of the indel. Similar to the previous bit of code, what follows just checks if a line in the .csv file (`csv`) is in the 180StrainsRead file (`reads`), and then just copies the line into the new IndividualIndels file (`newDataFile`), while inserting a column that includes the length of the indel in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv = open('/home/mdrichard05/Dropbox/CompensatoryIndels/Data/Genomes/samtools.2.1.s.filled.e.noimpute.csv')\n",
    "reads = open('/home/mdrichard05/Dropbox/CompensatoryIndels/Data/Processed/180StrainsRead.txt')\n",
    "\n",
    "newDataFile = open('/home/mdrichard05/Dropbox/CompensatoryIndels/Data/Processed/IndividualIndels.txt','w')\n",
    "\n",
    "##sort csv, reads into lists, create new list\n",
    "\n",
    "csvList = []\n",
    "for i in csv:\n",
    "    csvList.append(i.strip('\\n').split(','))\n",
    "\n",
    "readsList = []\n",
    "for i in reads:\n",
    "    readsList.append(i.strip('\\n').split('\\t'))\n",
    "\n",
    "csvList[0].insert(2,'len')\n",
    "csvList[0].insert(2,'gene')\n",
    "newDataList = []\n",
    "for i in range(1,len(csvList)):\n",
    "    newDataList.append(csvList[i])\n",
    "\n",
    "## Add the lengths into the data list\n",
    "\n",
    "c = 0\n",
    "for i in newDataList:\n",
    "    i.insert(2, readsList[c][2])\n",
    "    i.insert(2,readsList[c][4])\n",
    "    c += 1\n",
    "\n",
    "newDataList.insert(0,csvList[0])\n",
    "print(newDataList[0])\n",
    "\n",
    "## Write into file\n",
    "\n",
    "for line in newDataList:\n",
    "    for item in line:\n",
    "        newDataFile.write(item)\n",
    "        newDataFile.write(',')\n",
    "    newDataFile.write('\\n')\n",
    "\n",
    "csv.close()\n",
    "reads.close()\n",
    "newDataFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiate between Indels in Exon regions and Intron regions\n",
    "\n",
    "The next step is the most important one thus far, since all previous steps have just been filtering the data in pretty simple ways. Now, the goal is to separate indels by whether they occur in an exon or an intron. The adjustedAnnotation file has this information, and the difficulty is that many indels have multiple isoforms. To recreate the data, it is necessary to look at the what isoforms they chose.\n",
    "*Not on campus, so I cannot access the methods section of the online paper.*\n",
    "It is also necessary to remember that the indels that exist in exon regions must also be in a coding region, otherwise it is not of interest.\n",
    "\n",
    "For now, the choice was made to exclusively use the first isoform for each indel. The code below creates two files: IndividualIntronsNew, and IndividualExonsNew. This is because IndividiualExons/Introns (without the \"New\") were created before, but erroneously. They are only kept for the purpose of having a header reference, as shown in the declaration of `getHeader` in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annot = open('/home/mdrichard05/Dropbox/CompensatoryIndels/Data/Processed/adjustedAnnotation.txt')\n",
    "indiv = open('/home/mdrichard05/Dropbox/CompensatoryIndels/Data/Processed/IndividualIndels.txt')\n",
    "introns = open('/home/mdrichard05/Dropbox/CompensatoryIndels/Data/Processed/IndividualIntronsNew.txt','w')\n",
    "exons = open('/home/mdrichard05/Dropbox/CompensatoryIndels/Data/Processed/IndividualExonsNew.txt','w')\n",
    "\n",
    "getHeader = open('/home/mdrichard05/Dropbox/CompensatoryIndels/Data/Processed/IndividualExons.txt')\n",
    "header = getHeader.readline()\n",
    "getHeader.close()\n",
    "\n",
    "anList = []\n",
    "for i in annot:\n",
    "    anList.append(i.strip('\\n').split('\\t')[0:12])\n",
    "annot.close()\n",
    "\n",
    "indivList = []\n",
    "for i in indiv:\n",
    "    indivList.append(i.strip('\\n').split(',')[0:184])\n",
    "indiv.close()\n",
    "\n",
    "intronList = []\n",
    "exonList = []\n",
    "\n",
    "for i in anList[::2]:\n",
    "    if i[9][3] == 'i':\n",
    "        intronList.append([i[0],i[1]])\n",
    "    else:\n",
    "        if i[10][3] == 'C':\n",
    "            exonList.append([i[0],i[1]])\n",
    "\n",
    "indivIntronList = []\n",
    "indivExonList = []\n",
    "\n",
    "## print(intronList[0],intronList[-1])\n",
    "introns.write(header)\n",
    "exons.write(header)\n",
    "for i in range(1,len(indivList)):\n",
    "    if [indivList[i][0], indivList[i][1]] in intronList:\n",
    "        for k in range(0, len(indivList[i])-1):\n",
    "            introns.write(indivList[i][k])\n",
    "            introns.write(',')\n",
    "        introns.write(indivList[i][-1])    \n",
    "        introns.write('\\n')\n",
    "    if [indivList[i][0], indivList[i][1]] in exonList:\n",
    "        for k in range(0, len(indivList[i])-1):\n",
    "            exons.write(indivList[i][k])\n",
    "            exons.write(',')\n",
    "        exons.write(indivList[i][-1])\n",
    "        exons.write('\\n')\n",
    "        \n",
    "introns.close()\n",
    "exons.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, the code is just skipping every other line of the adjustedAnnotation file (remember, only the first line in each pair is referenced in other files). It then checks if the first isoform starts with an \"i\" (for intron). If so, it gets put into the intron list, and printed into the IndividualIntronsNew (`introns`) file. If it does not start with an \"i\", it is an exon. So, we just look at the next column, which tells us if the first isoform is in a UTR region, or a CDS region. If it is in a CDS region (starts with \"C\"), it is an indel we are interested in, and it gets put into the IndividualExonsNew (`exons`) file."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
